{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/mnist-in-csv/mnist_test.csv\n/kaggle/input/mnist-in-csv/mnist_train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport csv\ntrain_x,train_y=[],[]\ncolum=None\nwith open('/kaggle/input/mnist-in-csv/mnist_train.csv','r') as file:\n    reader=csv.reader(file,delimiter=',')\n    next(reader)\n    for row in reader:\n        train_x.append(row[1:])\n        train_y.append(int(row[0]))","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"'2.1.0'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nntrain=len(train_x)\ndim=int(np.sqrt(len(train_x[0])))","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_input=np.array(train_x).reshape(ntrain,dim,dim)\n\ninput_dim=train_input.shape","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label=tf.keras.utils.to_categorical(np.array(train_y),10)\ntrain_input=train_input.reshape(ntrain,dim,dim,1)\nprint(train_label.shape)\nprint(train_input.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"(60000, 10)\n(60000, 28, 28, 1)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D,Dense,MaxPool2D,Flatten\nfrom tensorflow.keras.layers import BatchNormalization,Dropout\n\nmodel=Sequential([\n    Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=(28,28,1)),\n    MaxPool2D((2,2)),\n    BatchNormalization(),\n    Dropout(0.2),\n    Conv2D(32,kernel_size=(3,3),activation='relu'),\n    MaxPool2D((2,2)),\n    BatchNormalization(),\n    Dropout(0.2),\n    Flatten(),\n    Dense(64,activation='relu'),\n    Dense(10,activation='softmax')\n])","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_gen=ImageDataGenerator(rescale=1/255.0)\ntrain_data_gen=train_gen.flow(train_input,train_label,batch_size=32)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x,test_y=[],[]\nwith open('/kaggle/input/mnist-in-csv/mnist_test.csv','r') as file:\n    reader=csv.reader(file,delimiter=',')\n    next(reader)\n    for row in reader:\n        test_x.append(row[1:])\n        test_y.append(int(row[0]))\nntest=len(test_y)\ndim_t=int(np.sqrt(len(test_x[0])))\ntest_input=np.array(test_x)\ntest_input=test_input.reshape(ntest,dim_t,dim_t,1)\ntest_output=tf.keras.utils.to_categorical(np.array(test_y),10)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen=ImageDataGenerator(rescale=1/255.0)\ntest_data_gen=test_gen.flow(test_input,test_output,batch_size=32)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory=model.fit_generator(train_data_gen,epochs=15,validation_data=test_data_gen)","execution_count":12,"outputs":[{"output_type":"stream","text":"Train for 1875 steps, validate for 313 steps\nEpoch 1/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0688 - val_accuracy: 0.9842\nEpoch 2/20\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0743 - val_accuracy: 0.9852\nEpoch 3/20\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.0046 - accuracy: 0.9984 - val_loss: 0.0686 - val_accuracy: 0.9850\nEpoch 4/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0677 - val_accuracy: 0.9871\nEpoch 5/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0036 - accuracy: 0.9987 - val_loss: 0.0771 - val_accuracy: 0.9841\nEpoch 6/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0812 - val_accuracy: 0.9856\nEpoch 7/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0753 - val_accuracy: 0.9851\nEpoch 8/20\n1875/1875 [==============================] - 10s 5ms/step - loss: 0.0030 - accuracy: 0.9990 - val_loss: 0.0736 - val_accuracy: 0.9862\nEpoch 9/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0797 - val_accuracy: 0.9850\nEpoch 10/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0784 - val_accuracy: 0.9860\nEpoch 11/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0849 - val_accuracy: 0.9838\nEpoch 12/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0829 - val_accuracy: 0.9853\nEpoch 13/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0778 - val_accuracy: 0.9857\nEpoch 14/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0020 - accuracy: 0.9993 - val_loss: 0.0815 - val_accuracy: 0.9873\nEpoch 15/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 8.4233e-04 - accuracy: 0.9997 - val_loss: 0.0759 - val_accuracy: 0.9876\nEpoch 16/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 0.0835 - val_accuracy: 0.9871\nEpoch 17/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0023 - accuracy: 0.9991 - val_loss: 0.0910 - val_accuracy: 0.9871\nEpoch 18/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 0.0868 - val_accuracy: 0.9869\nEpoch 19/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0924 - val_accuracy: 0.9859\nEpoch 20/20\n1875/1875 [==============================] - 9s 5ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0875 - val_accuracy: 0.9871\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}